{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDS 303 Group 3 Project: Phishing and Spam Categorization Code\n",
    "### Outline of Code\n",
    "- Importing the Cleaned Data With Unique Features\n",
    "- Logistic Regression\n",
    "- Exploration of Alternative Models\n",
    "- Importing Tokenized and Vectorized Emails\n",
    "- Apply the same models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification training dataset shape is: (12670, 19) Testing dataset shape is: (5431, 19)\n",
      "Regression train/test split is: 0.7 / 0.3\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn import datasets, model_selection, metrics\n",
    "from sklearn import linear_model, naive_bayes, tree\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Importing Data\n",
    "df = pd.read_csv(\"../CDS303/CSV Files/Post_EDA_encoded_df.csv\")\n",
    "df.head()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "y = df['Safe_Email']\n",
    "X = df.drop(['Safe_Email'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Splitting the Data, Training versus Testing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y, test_size=0.3)\n",
    "\n",
    "X_train_pct = round((len(X_train) / (len(X_train) + len(X_test))), 2)\n",
    "X_test_pct = round((len(X_test) / (len(X_train) + len(X_test))), 2)\n",
    "\n",
    "print('Classification training dataset shape is:', X_train.shape, 'Testing dataset shape is:', X_test.shape)\n",
    "print('Regression train/test split is:', X_train_pct, '/', X_test_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Creation and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.746646</td>\n",
       "      <td>0.724053</td>\n",
       "      <td>0.947843</td>\n",
       "      <td>0.820970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.756117</td>\n",
       "      <td>0.736469</td>\n",
       "      <td>0.937540</td>\n",
       "      <td>0.824929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.752170</td>\n",
       "      <td>0.734415</td>\n",
       "      <td>0.933033</td>\n",
       "      <td>0.821894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.756511</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.945911</td>\n",
       "      <td>0.826442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.769534</td>\n",
       "      <td>0.739259</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.836780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.756196</td>\n",
       "      <td>0.733593</td>\n",
       "      <td>0.945654</td>\n",
       "      <td>0.826203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score\n",
       "0     1  0.746646   0.724053  0.947843  0.820970\n",
       "1     2  0.756117   0.736469  0.937540  0.824929\n",
       "2     3  0.752170   0.734415  0.933033  0.821894\n",
       "3     4  0.756511   0.733766  0.945911  0.826442\n",
       "4     5  0.769534   0.739259  0.963941  0.836780\n",
       "5  Mean  0.756196   0.733593  0.945654  0.826203"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Define your logistic regression model\n",
    "logistic_model = linear_model.LogisticRegression()\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for each fold\n",
    "fold_results = []\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    logistic_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Make predictions on the validation fold\n",
    "    y_pred_fold = logistic_model.predict(X_val_fold)\n",
    "    \n",
    "    # Evaluate the model on the validation fold\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    precision = precision_score(y_val_fold, y_pred_fold)\n",
    "    recall = recall_score(y_val_fold, y_pred_fold)\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    # Store the results for this fold\n",
    "    fold_results.append({'Fold': fold_idx,\n",
    "                         'Accuracy': accuracy,\n",
    "                         'Precision': precision,\n",
    "                         'Recall': recall,\n",
    "                         'F1 Score': f1})\n",
    "\n",
    "# Create a DataFrame to store the fold-wise results\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "# Calculate mean scores across all folds\n",
    "mean_scores = results_df.mean(axis=0)\n",
    "\n",
    "# Create a DataFrame for mean scores\n",
    "mean_scores_df = pd.DataFrame(mean_scores).transpose()\n",
    "\n",
    "# Set the 'Fold' column to 'Mean' for the mean scores DataFrame\n",
    "mean_scores_df['Fold'] = 'Mean'\n",
    "\n",
    "# Concatenate the mean scores DataFrame with the original results DataFrame\n",
    "results_df = pd.concat([results_df, mean_scores_df], ignore_index=True)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model, but we have unbalanced classes. Because there are approximately 11,000 safe emails versus 7,000 unsafe emails, we use stratified k-fold cross validation.\n",
    "\n",
    "The model has a mean accuracy of .75 across all 5 of the folds. This is the overall correctness of the model. It is measured by taking the overall correct predictions divided by the total number of cases examined. Precision refers to the accuracy of the positive predictions. Recall is important when the cost of a false negative is high because it is a measure of the actual positives identified by the model. Finally, the F-Score capture the precision and recall in one number.\n",
    "\n",
    "- Accuracy= TP+TN+FP+FN / TP+TN\n",
    "\n",
    "- Precision= TP / TP+FP\n",
    "\n",
    "- Recall= TP / TP+FN\n",
    "\n",
    "- F1 Score= 2 x (Precision x Recall) / (Precision + Recall)\n",
    "\n",
    "This Accuracy score seems quite low for the use case. We would like to predict the type of emails at least 95% of the time. The following section we explore the hyperparameter space for Logarithmic Regression.\n",
    "\n",
    "#### Hyperparameter Search\n",
    "There are 5 different hyperparameters for the logistic regression model. We perform a grid search to find the best hyperparameter. We will use the F1 score as our primary consideration for comparing the models with different hyperparameters because we have imbalanced classes and want to account for both the perfomance of the model on precision and recall.\n",
    "\n",
    "One significant Hyperparameter is the C (Inverse Regularization Strength). This is used to prevent overfitting. A high value of C means there is less regularization and the risk of overfitting. A low vaule means there is a risk of underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "# Ignore FitFailedWarning, because some of the combinations of hyperparameters are expected to not converge\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "\n",
    "# Grid of parameters to search over\n",
    "param_grid = [\n",
    "    {'penalty': ['l1', 'l2'], 'solver': ['liblinear'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    {'penalty': ['l2', 'none'], 'solver': ['newton-cg', 'lbfgs', 'sag'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    {'penalty': ['elasticnet'], 'solver': ['saga'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'l1_ratio': np.linspace(0, 1, 10)}\n",
    "]\n",
    "\n",
    "# GridSearchCV to find the best parameters, score on f1 to balance the consideration of performance on recall and precision\n",
    "clf = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and best score\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(clf.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Interpretation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on Email Text Data\n",
    "### The Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
